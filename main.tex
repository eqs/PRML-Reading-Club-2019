\documentclass[10pt]{beamer}

\usepackage{amsmath,amssymb}
\usepackage{zxjatype}
\usepackage[ipa]{zxjafont}
\usetheme{metropolis}
\usepackage{tikz}
\usepackage{tikzsymbols}
\usepackage{appendixnumberbeamer}
\usepackage{bm}

\usefonttheme{professionalfonts}
\usetikzlibrary{positioning}

% -- block color ---
\setbeamercolor{block title}{use=structure, fg=white!90!purple, bg=purple!75!black}
\setbeamercolor{block body}{use=structure, fg=black!90!white, bg=white!90!black}
\setbeamercolor{block title example}{use=structure, fg=white!90!cyan, bg=cyan!75!black}
\setbeamercolor{block body example}{use=structure, fg=black!90!white, bg=white!90!black}

% --- page number ---
\setbeamertemplate{footline}{%
	\raisebox{10pt}{\makebox[\paperwidth]{\hfill\makebox[7em]{\normalsize\texttt{\insertframenumber/\inserttotalframenumber}}}}%
}

% --- title logo ---

\newcommand{\myinsertlogo}[1]{%
\begin{tikzpicture}[overlay, remember picture]
    \node[above left=1cm and .8cm of current page.south east] {\includegraphics[width=2.25cm]{#1}};
\end{tikzpicture}}

% --- commands ---

\newcommand{\redtext}[1]{\textcolor{red}{#1}}
\newcommand{\bluetext}[1]{\textcolor{blue}{#1}}
\newcommand{\highlight}[2][yellow]{\tikz[baseline=(x.base)]{\node[rectangle,rounded corners,fill=#1!10](x){$#2$};}}
\newcommand{\highlightcap}[3][yellow]{\tikz[baseline=(x.base)]{\node[rectangle,rounded corners,fill=#1!10](x){$#2$} node[below of=x, node distance=2em, color=#1]{#3};}}
\newcommand{\highlightcaphead}[3][yellow]{\tikz[baseline=(x.base)]{\node[rectangle,rounded corners,fill=#1!10](x){$#2$} node[above of=x, node distance=2em, color=#1]{#3};}}

\newenvironment{supframe}[1]{%
    \setbeamercolor{frametitle}{fg=white!90!purple, bg=mLightGreen!75!black}%
    \begin{frame}{#1}%
}{%
    \end{frame}%
}

\newcommand{\nbracket}[1]{\left( #1 \right)}
\newcommand{\cbracket}[1]{\left\{ #1 \right\}}
\newcommand{\rbracket}[1]{\left[ #1 \right]}
\newcommand{\abracket}[1]{\left\langle #1 \right\rangle}

\DeclareMathOperator{\tr}{tr}

\title{Probability Distributions (PRML \S2.3.1-2.3.7)}
\date{PRML Reading Club (June 3, 2019)}
\author{Satoshi Murashige}
\institute{Mathematical Informatics Lab., NAIST}

\begin{document}
    \begin{frame}[plain]
        \maketitle
        \myinsertlogo{naist.pdf}
    \end{frame}
    
    \begin{frame}{Table of Contents}
        \tableofcontents
    \end{frame}
    
    \begin{supframe}{Review: Multivariate Gaussian Distribution}
        Hello metropolis!
    \end{supframe}
    
    \begin{frame}{Completing the square (for univariate case)}
        \begin{itemize}
            \item Basic idea:
                \begin{align*}
                    &x^2 - 6x + 2 \\
                    \onslide*<2>{&= x^2 - 6x + 9 - 7 \\}
                    \onslide<3->{&= \highlight[red]{x^2 - 6x + 9} - 7 \\}
                    \onslide<4->{&= \highlight[red]{(x - 3)^2} - 7}
                \end{align*}
            \item Example:
                \begin{align*}
                    &\exp\left(-\frac{1}{2}x^2 + 2x + \mathrm{const.}\right) \\
                    \onslide<6->{&= \exp\left\{-\frac{1}{2}(x^2 - 4x + 4) + \mathrm{const.}\right\} \\}
                    \onslide*<7>{&= \exp\left\{-\dfrac{(x - 2)^2}{2}\right\}\cdot\exp(\mathrm{const.}) \\ }
                    \onslide<8->{&= \highlightcap[red]{\exp\left\{-\dfrac{(x - 2)^2}{2}\right\}}{\small Unnormalized Gaussian}\cdot\exp(\mathrm{const.}) }
                \end{align*}
        \end{itemize}
    \end{frame}
    
    \section{\S2.3.1 Conditional Gaussian Distribution}
    
    \begin{frame}{Conditional Gaussian Distribution}
        Now, we consider to derive the following properties
        \begin{block}{Properties of conditional Gaussian distribution}
            \begin{align*}
                &p(\mathbf x_a, \mathbf x_b) = p(\mathbf x) = \mathcal N(\mathbf x | \bm \mu, \bm \Sigma) 
                \Rightarrow 
                \begin{array}{l}
                     p(\mathbf x_a | \mathbf x_b) = \mathcal N(\mathbf x_a | \bm \mu_{a|b}, \bm \Sigma_{a|b})  \\
                     p(\mathbf x_a) = \mathcal N(\mathbf x_a | \bm \mu_a, \bm \Sigma_a) 
                \end{array}
            \end{align*}
        \end{block}
        \begin{center}
            \includegraphics[width=0.45\hsize]{figs/Figure2_9a.pdf}
            \hfill
            \includegraphics[width=0.45\hsize]{figs/Figure2_9b.pdf}
        \end{center}
    \end{frame}
    
    \begin{frame}{Examples of $\mathbf x_a$ and $\mathbf x_b$}
        \begin{exampleblock}{Sequence of a rocket's position}
            \begin{align*}
                &\mathbf x_a = x_{t+1} \\
                &\mathbf x_b = (x_1, x_2, \cdots, x_t)^\top
            \end{align*}
        \end{exampleblock}
    \end{frame}
    
    \begin{frame}{Definition of Notation}
        Consider a joint distribution $p(\mathbf x) = \mathcal N(\mathbf x | \bm \mu, \bm \Sigma)$
        \begin{itemize}
            \item Separate a $D$-dimensional vector $\mathbf x \sim \mathcal N(\mathbf x | \bm \mu, \bm \Sigma)$
                into $\mathbf x_a \in \mathbb R^M$ and $\mathbf x_b \in \mathbb R^{D-M}$
                \begin{align*}
                    \mathbf x &= \begin{pmatrix}
                        \mathbf x_a \\
                        \mathbf x_b 
                    \end{pmatrix} \tag{2.65}\\
                    \bm \mu &= \begin{pmatrix}
                        \bm \mu_a \\
                        \bm \mu_b 
                    \end{pmatrix} \tag{2.66}\\
                    \bm \Sigma &= \begin{pmatrix}
                        \bm \Sigma_{aa} & \bm \Sigma_{ab} \\
                        \bm \Sigma_{ba} & \bm \Sigma_{bb} 
                    \end{pmatrix} \tag{2.67}
                \end{align*}
        \end{itemize}
    \end{frame}

    \begin{frame}{Definition of Notations}
        \begin{align*}
            \bm\Lambda &\equiv \bm\Sigma^{-1} \tag{2.68} \\
            \bm\Lambda &= \begin{pmatrix}
                \bm \Lambda_{aa} & \bm \Lambda_{ab} \\
                \bm \Lambda_{ba} & \bm \Lambda_{bb} 
            \end{pmatrix} \tag{2.69}
        \end{align*}
    \end{frame}
    
    \begin{frame}{Derivation of Conditional Gaussian Distribution}
        From the product rule of probability, 
        \begin{align*}
            \highlightcap[blue]{p(\mathbf x_a | \mathbf x_b)}{Unknown}
            = \frac{\highlightcaphead[red]{p(\mathbf x_a, \mathbf x_b)}{Known}}{\highlightcap[blue]{p(\mathbf x_b)}{Unknown}}
        \end{align*}
        両辺の対数をとる
        \begin{align*}
            \ln p(\mathbf x_a | \mathbf x_b) 
            &= \ln p(\mathbf x_a, \mathbf x_b) + \mathrm{const.} \\
            &= -\frac{1}{2}(\mathbf x - \bm\mu)^\top\bm\Sigma^{-1}(\mathbf x - \bm\mu) + \mathrm{const.}
        \end{align*}

    \end{frame}
    
    \begin{frame}{Derivation of Conditional Gaussian Distribution}
        \begin{align*}
            &-\frac{1}{2}(\mathbf x - \bm\mu)^\top \bm\Sigma^{-1}(\mathbf x - \bm\mu) \\
            &=-\frac{1}{2}(\mathbf x_a - \bm\mu_a)^\top \bm\Lambda_{aa}(\mathbf x_a - \bm\mu_a)
            -\frac{1}{2}(\mathbf x_a - \bm\mu_a)^\top \bm\Lambda_{ab}(\mathbf x_b - \bm\mu_b) \\
            &\qquad -\frac{1}{2}(\mathbf x_b - \bm\mu_b)^\top \bm\Lambda_{ba}(\mathbf x_a - \bm\mu_a)
            -\frac{1}{2}(\mathbf x_b - \bm\mu_b)^\top \bm\Lambda_{bb}(\mathbf x_b - \bm\mu_b) \tag{2.70} \\
            %---------------
            &= -\frac{1}{2}\left( \highlight[red]{\mathbf x_a^\top\bm\Lambda_{aa}\mathbf x_a} - \highlight[red]{\mathbf x_a^\top\bm\Lambda_{aa}\bm\mu_a} - 
                               \highlight[red]{\bm\mu_a^\top\bm\Lambda_{aa}\mathbf x_a} + \bm\mu_a^\top\bm\Lambda_{aa}\bm\mu_a \right) \\
            &\qquad -\frac{1}{2}\left( \mathbf x_a^\top\bm\Lambda_{ab}\mathbf x_b - \highlight[red]{\mathbf x_a^\top\bm\Lambda_{ab}\bm\mu_b} - 
                               \bm\mu_a^\top\bm\Lambda_{ab}\mathbf x_b + \bm\mu_a^\top\bm\Lambda_{ab}\bm\mu_b \right) \\
            &\qquad -\frac{1}{2}\left( \mathbf x_b^\top\bm\Lambda_{ba}\mathbf x_a - \mathbf x_b^\top\bm\Lambda_{ba}\bm\mu_a - 
                               \highlight[red]{\bm\mu_b^\top\bm\Lambda_{ba}\mathbf x_a} + \bm\mu_b^\top\bm\Lambda_{ba}\bm\mu_a \right) \\
            &\qquad -\frac{1}{2}\left( \mathbf x_b^\top\bm\Lambda_{bb}\mathbf x_b - \mathbf x_b^\top\bm\Lambda_{bb}\bm\mu_b - 
                               \bm\mu_b^\top\bm\Lambda_{bb}\mathbf x_b + \bm\mu_b^\top\bm\Lambda_{bb}\bm\mu_b \right) \\
            &= \highlightcap[red]{\displaystyle -\frac{1}{2}\mathbf x_a^\top\bm\Lambda_{aa}\mathbf x_a}{\small The second order term}
                + \highlightcap[red]{\mathbf x_a^\top(\bm\Lambda_{aa}\bm\mu_a + \bm\Lambda_{ab}\bm\mu_b)}{The linear term}
                + \mathrm{const.}
        \end{align*}
    \end{frame}

    \begin{frame}{Derivation of Conditional Gaussian Distribution}
        \begin{block}{Completing the square}
            \begin{align*} -\frac{1}{2}(\mathbf x - \bm\mu)^\top \bm\Sigma^{-1}(\mathbf x - \bm\mu) =  -\frac{1}{2}\mathbf x^\top\bm\Sigma^{-1}\mathbf x + \mathbf x^\top\bm\Sigma^{-1}\bm\mu + \mathrm{const.} \tag{2.71}
            \end{align*}
        \end{block}\vspace{-5mm}
        \begin{align*}
            &-\frac{1}{2}(\mathbf x - \bm\mu)^\top \bm\Sigma^{-1}(\mathbf x - \bm\mu) \\
            &= -\frac{1}{2}\mathbf x_a^\top\bm\Lambda_{aa}\mathbf x_a
                + \mathbf x_a^\top(\bm\Lambda_{aa}\bm\mu_a + \bm\Lambda_{ab}\bm\mu_b)
                + \mathrm{const.} \\
            &=
            \onslide*<1>{
                -\frac{1}{2}\mathbf x_a^\top\bm\Lambda_{aa}\mathbf x_a
                    + \mathbf x_a^\top \bm\Lambda_{aa}\bm\Lambda_{aa}^{-1} (\bm\Lambda_{aa}\bm\mu_a + \bm\Lambda_{ab}\bm\mu_b)
                    + \mathrm{const.}
            }
            \onslide*<2->{
                -\frac{1}{2}\mathbf x_a^\top\highlightcap[red]{\bm\Lambda_{aa}}{$\bm\Sigma^{-1}$}\mathbf x_a
                    + \mathbf x_a^\top \highlightcap[red]{\bm\Lambda_{aa}}{$\bm\Sigma^{-1}$}
                    \highlightcap[blue]{\bm\Lambda_{aa}^{-1} (\bm\Lambda_{aa}\bm\mu_a + \bm\Lambda_{ab}\bm\mu_b)}{$\bm\mu$}
                    + \mathrm{const.} \\
            }
            \onslide<3->{
                &= -\frac{1}{2}(\mathbf x_a - \bm\mu_{a|b})^\top \bm\Sigma_{a|b}^{-1}(\mathbf x_a - \bm\mu_{a|b}) + \mathrm{const.}
            }
        \end{align*}\vspace{-4mm}
        \onslide<3->{
            \begin{align*}
                \bm\Sigma_{a|b} &= \bm\Lambda_{aa}^{-1} \tag{2.73}\\
                \bm\mu_{a|b} &= \bm\mu_a - \bm\Lambda_{aa}^{-1}\bm\Lambda_{ab}(\mathbf x_b - \bm\mu_b) \tag{2.75}
            \end{align*}
        }
    \end{frame}

    \begin{frame}{Derivation of Conditional Gaussian Distribution}
        わかったこと
        \begin{align*}
            \ln p(\mathbf x_a | \mathbf x_b) 
            &= -\frac{1}{2}(\mathbf x_a - \bm\mu_{a|b})^\top \bm\Sigma_{a|b}^{-1}(\mathbf x_a - \bm\mu_{a|b}) + \mathrm{const.}
        \end{align*}
        \begin{align*}
            \therefore \; & p(\mathbf x_a | \mathbf x_b) 
            \propto \exp\left\{-\frac{1}{2}(\mathbf x_a - \bm\mu_{a|b})^\top \bm\Sigma_{a|b}^{-1}(\mathbf x_a - \bm\mu_{a|b}) \right\} \\
            & \xrightarrow{\mathrm{Normalization}} p(\mathbf x_a | \mathbf x_b) = \mathcal N(\mathbf x_a | \bm\mu_{a|b}, \bm\Sigma_{a|b})
        \end{align*}
        \begin{align*}
            \bm\Sigma_{a|b} &= \bm\Lambda_{aa}^{-1} \tag{2.73}\\
            \bm\mu_{a|b} &= \bm\mu_a - \bm\Lambda_{aa}^{-1}\bm\Lambda_{ab}(\mathbf x_b - \bm\mu_b) \tag{2.75}
        \end{align*}
    \end{frame}

    \begin{frame}{Derivation of Conditional Gaussian Distribution}
    
    \end{frame}

    \begin{frame}{Derivation of Conditional Gaussian Distribution}
    
    \end{frame}

    \begin{frame}{Derivation of Conditional Gaussian Distribution}
    
    \end{frame}
    
    \begin{supframe}{Solution of Exercise 2.22}
        Let $\mathbf A$ be a symmetric matrix ($\mathbf A = \mathbf A^\top$).
        The inverse matrix $\mathbf A^{-1}$ satisfies
        \[
            \mathbf A\mathbf A^{-1} = \mathbf I.
        \]
        By taking the transpose of both sides of this equation, 
        we obtain
        \[
            (\mathbf A^{-1})^\top \mathbf A^\top = \mathbf I.
        \]
        From the definition of inverse matrix, we obtain
        \[
            (\mathbf A^{-1})^\top = \mathbf A^{-1}.
        \]
        Therefore, $\mathbf A^{-1}$ is also symmetric matrix.
        

    \end{supframe}

    
    \begin{frame}{Title}
        \begin{block}{Closed form of conditional Gaussian distribution (still using $\bm\Lambda_{**}$)}
            \begin{align*}
                 &p(\mathbf x_a | \mathbf x_b) = \mathcal N(\mathbf x_a | \bm \mu_{a|b}, \bm \Sigma_{a|b})  \\
                 &
                 \begin{cases}
                 \bm\Sigma_{a|b} = \bm\Lambda_{aa}^{-1} \\
                 \bm\mu_{a|b} = \bm\mu_a - \bm\Lambda_{aa}^{-1}\bm\Lambda_{ab}(\mathbf x_a - \bm\mu_b)
                 \end{cases}
            \end{align*}
        \end{block}
        \begin{itemize}
            \item Where, we don't know a form of $\bm\Lambda_{aa}$ and $\bm\Lambda_{ab}$
        \end{itemize}
    \end{frame}
    
    \begin{frame}{Derivation of closed form of $\bm\Lambda_{**}$}
        \begin{block}{Exercise 2.24}
            \begin{align*}
                \begin{pmatrix}
                    \mathbf A & \mathbf B \\
                    \mathbf C & \mathbf D
                \end{pmatrix}^{-1} &= 
                \begin{pmatrix}
                    \mathbf M & -\mathbf M\mathbf B\mathbf D^{-1} \\
                    -\mathbf D^{-1}\mathbf C\mathbf M & \mathbf D^{-1}+\mathbf D^{-1}\mathbf C\mathbf M \mathbf B \mathbf D^{-1}
                \end{pmatrix} \tag{2.76}\\
                \mathbf M &= (\mathbf A - \mathbf B\mathbf D^{-1}\mathbf C)^{-1} \tag{2.77}
            \end{align*}
        \end{block}
        \begin{itemize}
            \item By applying above equations to
            \[
                \begin{pmatrix}
                    \bm \Sigma_{aa} & \bm \Sigma_{ab} \\
                    \bm \Sigma_{ba} & \bm \Sigma_{bb} 
                \end{pmatrix}^{-1}
                =
                \begin{pmatrix}
                    \bm \Lambda_{aa} & \bm \Lambda_{ab} \\
                    \bm \Lambda_{ba} & \bm \Lambda_{bb} 
                \end{pmatrix}, \tag{2.78}
            \]
            \item we cant get
            \begin{align*}
            \end{align*}
        \end{itemize}
    \end{frame}
    
    \begin{frame}{Title}
        \begin{block}{Closed form of conditional Gaussian distribution}
            \begin{align*}
                &p(\mathbf x_a | \mathbf x_b) = \mathcal N(\mathbf x_a | \bm \mu_{a|b}, \bm \Sigma_{a|b})  \\
                &\bm\mu_{a|b} = \bm\mu_a - \bm\Sigma_{ab}\bm\Sigma_{bb}^{-1}(\mathbf x_b - \bm\mu_b) \tag{2.81}\\
                &\bm\Sigma_{a|b} = \bm\Sigma_{aa}-\bm\Sigma_{ab}\bm\Sigma_{bb}^{-1}\bm\Sigma_{ba} \tag{2.82}
            \end{align*}
        \end{block}
    \end{frame}
    
    \section{\S2.3.2 Marginal Gaussian Distribution}
    
    \begin{frame}{Derivation of Marginal Gaussian Distribution}
        \begin{align*}
            p(\mathbf x_a) &= \int p(\mathbf x_a, \mathbf x_b) \:\mathrm d\mathbf x_b \tag{2.83}\\
            &= \int \frac{1}{(2\pi)^{D/2}|\bm\Sigma|^{1/2}}\exp\left\{ -\frac{1}{2}(\mathbf x - \bm\mu)^\top \bm\Sigma^{-1}(\mathbf x - \bm\mu) \right\} \:\mathrm d\mathbf x_b \\
            &= \int \mathrm{const.} \cdot \exp(\redtext{\mbox{The terms involving $\mathbf x_b$}}) \cdot \exp(\bluetext{\mbox{Other terms}}) \:\mathrm d\mathbf x_b \\
            &= \mathrm{const.}\cdot \exp(\bluetext{\mbox{Other terms}}) \int \exp(\redtext{\mbox{The terms involving $\mathbf x_b$}}) \:\mathrm d\mathbf x_b
        \end{align*}
    \end{frame}
    
    \begin{frame}{Derivation of Marginal Gaussian Distribution}
        \begin{align*}
            &-\frac{1}{2}(\mathbf x - \bm\mu)^\top \bm\Sigma^{-1}(\mathbf x - \bm\mu) \\
            &=-\frac{1}{2}(\mathbf x_a - \bm\mu_a)^\top \bm\Lambda_{aa}(\mathbf x_a - \bm\mu_a)
            -\frac{1}{2}(\mathbf x_a - \bm\mu_a)^\top \bm\Lambda_{ab}(\mathbf x_b - \bm\mu_b) \\
            &\qquad -\frac{1}{2}(\mathbf x_b - \bm\mu_b)^\top \bm\Lambda_{ba}(\mathbf x_a - \bm\mu_a)
            -\frac{1}{2}(\mathbf x_b - \bm\mu_b)^\top \bm\Lambda_{bb}(\mathbf x_b - \bm\mu_b) \tag{2.70} \\
            %---------------
            &= -\frac{1}{2}\left( \mathbf x_a^\top\bm\Lambda_{aa}\mathbf x_a - \mathbf x_a^\top\bm\Lambda_{aa}\bm\mu_a - 
                               \bm\mu_a^\top\bm\Lambda_{aa}\mathbf x_a + \bm\mu_a^\top\bm\Lambda_{aa}\bm\mu_a \right) \\
            &\qquad -\frac{1}{2}\left( \highlight[red]{\mathbf x_a^\top\bm\Lambda_{ab}\mathbf x_b} - \mathbf x_a^\top\bm\Lambda_{ab}\bm\mu_b - 
                               \highlight[red]{\bm\mu_a^\top\bm\Lambda_{ab}\mathbf x_b} + \bm\mu_a^\top\bm\Lambda_{ab}\bm\mu_b \right) \\
            &\qquad -\frac{1}{2}\left( \highlight[red]{\mathbf x_b^\top\bm\Lambda_{ba}\mathbf x_a} - \highlight[red]{\mathbf x_b^\top\bm\Lambda_{ba}\bm\mu_a} - 
                               \bm\mu_b^\top\bm\Lambda_{ba}\mathbf x_a + \bm\mu_b^\top\bm\Lambda_{ba}\bm\mu_a \right) \\
            &\qquad -\frac{1}{2}\left( \highlight[red]{\mathbf x_b^\top\bm\Lambda_{bb}\mathbf x_b} - \highlight[red]{\mathbf x_b^\top\bm\Lambda_{bb}\bm\mu_b} - 
                               \highlight[red]{\bm\mu_b^\top\bm\Lambda_{bb}\mathbf x_b} + \bm\mu_b^\top\bm\Lambda_{bb}\bm\mu_b \right) \\
            &= -\frac{1}{2}\mathbf x_b^\top\bm\Lambda_{bb}\mathbf x_b + \mathbf x_b^\top \left\{ \bm\Lambda_{bb}\bm\mu_b - \bm\Lambda_{ba}(\mathbf x_a - \bm\mu_a) \right\} 
                + \mbox{\bluetext{Other terms}} \\
            &= -\frac{1}{2}\mathbf x_b^\top\bm\Lambda_{bb}\mathbf x_b + \mathbf x_b^\top \mathbf m + \mbox{\bluetext{Other terms}} \;\;\;
                (\mathbf m = \bm\Lambda_{bb}\bm\mu_b - \bm\Lambda_{ba}(\mathbf x_a - \bm\mu_a))
        \end{align*}
    \end{frame}
    
    \begin{frame}{Derivation of Marginal Gaussian Distribution}
        \vspace*{-5mm}
        \begin{align*}
            -\frac{1}{2}(\mathbf x - \bm\mu)^\top \bm\Sigma^{-1}(\mathbf x - \bm\mu)
            &= \highlightcap[red]{\displaystyle -\frac{1}{2}\mathbf x_b^\top\bm\Lambda_{bb}\mathbf x_b + \mathbf x_b^\top \mathbf m}{The terms involving $\mathbf x_b$} + \mbox{\bluetext{Other terms}}
        \end{align*}
        \begin{block}{Completing the square}
            \begin{align*} -\frac{1}{2}(\mathbf x - \bm\mu)^\top \bm\Sigma^{-1}(\mathbf x - \bm\mu) =  -\frac{1}{2}\mathbf x^\top\bm\Sigma^{-1}\mathbf x + \mathbf x^\top\bm\Sigma^{-1}\bm\mu + \mathrm{const.} \tag{2.71}
            \end{align*}
        \end{block}\vspace{-5mm}
        \begin{align*} &-\frac{1}{2}(\mathbf x - \bm\mu)^\top \bm\Sigma^{-1}(\mathbf x - \bm\mu) = -\frac{1}{2}\mathbf x_b^\top\bm\Lambda_{bb}\mathbf x_b + \mathbf x_b^\top \mathbf m + \mbox{\bluetext{Other terms}} \\
            =& -\frac{1}{2}\mathbf x_b^\top\highlightcap[cyan]{\bm\Lambda_{bb}}{$\bm\Sigma^{-1}$}\mathbf x_b + \mathbf x_b^\top \highlightcap[cyan]{\bm\Lambda_{bb}}{$\bm\Sigma^{-1}$}\highlightcap[green]{\bm\Lambda_{bb}^{-1}\mathbf m}{$\bm\mu$} + \mbox{\bluetext{Other terms}} \\
            =& -\frac{1}{2}(\mathbf x_b - \bm\Lambda_{bb}^{-1}\mathbf m)^\top\bm\Lambda_{bb}(\mathbf x_b - \bm\Lambda_{bb}^{-1}\mathbf m)
                +\frac{1}{2}\mathbf m^\top\bm\Lambda_{bb}^{-1}\mathbf m + \mbox{\bluetext{Other terms}} \tag{2.84'}
        \end{align*}
    \end{frame}
    
    \begin{frame}{Derivation of Marginal Gaussian Distribution}
        \begin{align*}
            p(\mathbf x_a) &= \int p(\mathbf x_a, \mathbf x_b) \:\mathrm d\mathbf x_b \tag{2.83}\\
            &= \mathrm{const.}\cdot \exp(\bluetext{\mbox{Other terms}}) \int \exp(\redtext{\mbox{The terms involving $\mathbf x_b$}}) \:\mathrm d\mathbf x_b \\
            &= \mathrm{const.}\cdot \exp(\bluetext{\mbox{Other terms}}) \cdot \exp\left( \frac{1}{2}\mathbf m^\top\bm\Lambda_{bb}^{-1}\mathbf m\right) \\
            &\qquad \cdot \int \highlightcap[cyan]{\displaystyle \exp\left\{ -\frac{1}{2}(\mathbf x_b - \bm\Lambda_{bb}^{-1}\mathbf m)^\top\bm\Lambda_{bb}(\mathbf x_b - \bm\Lambda_{bb}^{-1}\mathbf m) \right\}}{An unnormalized Gaussian (2.86)} \:\mathrm d\mathbf x_b \\
            &= \mathrm{const.}\cdot 
                \highlightcap[blue]{\displaystyle \exp(\mbox{Other terms}) \cdot \exp\left( \frac{1}{2}\mathbf m^\top\bm\Lambda_{bb}^{-1}\mathbf m\right)}{The terms involving $\mathbf x_a$}
        \end{align*}
    \end{frame}
    
    \begin{frame}{Derivation of Marginal Gaussian Distribution}
        Where,
        \begin{align*}
            \mbox{\bluetext{Other terms}} &= -\frac{1}{2}\mathbf x_a^\top\bm\Lambda_{aa}\mathbf x_a + \mathbf x_a^\top\bm\Lambda_{aa}\bm\mu_a
                + \mathbf x_a^\top\bm\Lambda_{ab}\bm\mu_b + \highlightcap[cyan]{\mathrm{const.}}{\small Independent of $\mathbf x_a$} \\
                &= -\frac{1}{2}(\mathbf x_a - \bm\mu_a)^\top\bm\Lambda_{aa}(\mathbf x_a - \bm\mu_a) + \mathbf x_a^\top\bm\Lambda_{ab}\bm\mu_b + \highlight[cyan]{\mathrm{const.}} \\
            \frac{1}{2}\mathbf m^\top\bm\Lambda_{bb}^{-1}\mathbf m &= 
                \frac{1}{2}(\mathbf x_a - \bm\mu_a)\top\bm\Lambda_{ab}\bm\Lambda_{bb}^{-1}\bm\Lambda_{ba}(\mathbf x_a - \bm\mu_a)
                - \mathbf x_a^\top\bm\Lambda_{ab}\bm\mu_b + \highlight[cyan]{\mathrm{const.}}
        \end{align*}
        \begin{align*}
            \therefore\; &\mbox{\bluetext{Other terms}} + \frac{1}{2}\mathbf m^\top\bm\Lambda_{bb}^{-1}\mathbf m \\
            &= -\frac{1}{2}(\mathbf x_a - \bm\mu_a)^\top(\bm\Lambda_{aa} - \bm\Lambda_{ab}\bm\Lambda_{bb}^{-1}\bm\Lambda_{ba})(\mathbf x_a - \bm\mu_a) + \mathrm{const.} \\
            &\Rightarrow
            \begin{cases}
                \mathbb E[\mathbf x_a] = \bm\mu_a \\
                \mathrm{cov}[\mathbf x_a] = (\bm\Lambda_{aa} - \bm\Lambda_{ab}\bm\Lambda_{bb}^{-1}\bm\Lambda_{ba})^{-1}
            \end{cases}
        \end{align*}
    \end{frame}
    
    \begin{frame}{Derivation of Marginal Gaussian Distribution}
    
    \end{frame}
    
    \begin{frame}{Derivation of Marginal Gaussian Distribution}
    
    \end{frame}
    
    \begin{frame}{Title}
        \begin{align*}
            p(\mathbf x_a) = \int p(\mathbf x_a, \mathbf x_b)\; \mathrm d\mathbf x_b
        \end{align*}
        Hello metropolis!
    \end{frame}
    \begin{frame}{Linear Gaussian Model}
        \begin{align*}
            \mathbf y = \mathbf A \mathbf x + \mathbf b + \bm \epsilon, \;\; \bm \epsilon \sim \mathcal N(\bm\epsilon\:|\: \mathbf 0, \mathbf L^{-1})
        \end{align*}
    \end{frame}
    \begin{frame}{Title}
        Hello metropolis!
    \end{frame}
    \begin{frame}{Title}
        Hello metropolis!
    \end{frame}
    \begin{frame}{Student's t-distribution}
        \begin{itemize}
            \item Motivation: Marginalize precision of Gaussin distribution
        \end{itemize}
    \end{frame}
    
    \section{\S2.3.3 Bayes' theorem for Gaussian variables}
    
    \begin{frame}{Linear Gaussian Model}
        \begin{align*}
            p(\mathbf x) &= \mathcal N(\mathbf x | \bm\mu, \bm\Lambda^{-1}) \tag{2.99} \\
            p(\mathbf x | \mathbf y) &= \mathcal N(\mathbf y | \mathbf A\mathbf x + \mathbf b, \mathbf L^{-1}) \tag{2.100} \\
        \end{align*}
    \end{frame}
    
    \begin{frame}{Title}
        \begin{align*}
            \mathbf z &= \begin{pmatrix}
                \mathbf x \\ \mathbf y
            \end{pmatrix} \tag{2.101}
        \end{align*}
    \end{frame}
    
    \begin{frame}{Derivation of Joint Distribution $p(\mathbf z)$}
        From the product rule of probability, 
        \begin{align*}
            p(\mathbf z) = 
            \highlightcap[blue]{p(\mathbf x, \mathbf y)}{Unknown}
            = \highlightcap[red]{p(\mathbf y | \mathbf x)}{Known} \times \highlightcap[red]{p(\mathbf x)}{Known}
        \end{align*}
        Take logarithm of both sides, 
        \begin{align*}
            \ln p(\mathbf z) 
            &= \ln p(\mathbf x) + \ln p(\mathbf y | \mathbf x) \\
            &= -\frac{1}{2}(\mathbf x - \bm\mu)^\top\bm\Lambda(\mathbf x - \bm\mu) \\
            &\quad -\frac{1}{2}(\mathbf y - \mathbf A\mathbf x - \mathbf b)^\top\mathbf L(\mathbf y - \mathbf A\mathbf x - \mathbf b)
                + \mathrm{const.} \tag{2.102}
        \end{align*}
        Where, (2.102) is a quadratic function of $\mathbf x$ and $\mathbf y$. \par
        $\Rightarrow$ $p(\mathbf z)$ is Gaussian distribuiton. \par
        $\Rightarrow$ Completing the square!
    \end{frame}
    
    \begin{frame}{Derivation of Joint Distribution $p(\mathbf z)$}
        \begin{align*}
            \ln p(\mathbf z) 
            &= \ln p(\mathbf x) + \ln p(\mathbf y | \mathbf x) \\
            &= -\frac{1}{2}(\mathbf x - \bm\mu)^\top\bm\Lambda(\mathbf x - \bm\mu) 
            -\frac{1}{2}(\mathbf y - \mathbf A\mathbf x - \mathbf b)^\top\mathbf L(\mathbf y - \mathbf A\mathbf x - \mathbf b)
                + \mathrm{const.} \tag{2.102} \\
            &= -\frac{1}{2}(\highlight[red]{\mathbf x^\top\bm\Lambda\mathbf x} - \highlight[blue]{\mathbf x^\top\bm\Lambda\bm\mu} - \highlight[blue]{\bm\mu^\top\bm\Lambda\mathbf x} 
            + \bm\mu^\top\bm\Lambda\bm\mu) \\
            &\quad -\frac{1}{2}(\highlight[red]{\mathbf y^\top\bm\Lambda\mathbf y} - \highlight[red]{\mathbf y^\top\mathbf L\bm\Lambda\mathbf x} 
            - \highlight[blue]{\mathbf y^\top\mathbf L\mathbf b} - \highlight[red]{\mathbf x^\top\mathbf A^\top\mathbf L\mathbf y} 
            - \highlight[blue]{\mathbf b^\top\mathbf L\mathbf y} \\
            &\qquad + \highlight[red]{\mathbf x^\top\mathbf A^\top\mathbf L\mathbf A\mathbf x} + \highlight[blue]{\mathbf x^\top\mathbf A^\top\mathbf L\mathbf b}
                + \highlight[blue]{\mathbf b^\top\mathbf L\mathbf A\mathbf x} + \mathbf b^\top\mathbf L\mathbf b)+ \mathrm{const.} \\
            &= \highlightcap[red]{\displaystyle -\frac{1}{2}\mathbf x^\top(\bm\Lambda + \mathbf A^\top\mathbf L\mathbf A)\mathbf x
                -\frac{1}{2} \mathbf y^\top\mathbf L\mathbf y 
                +\frac{1}{2} \mathbf y^\top\mathbf L\mathbf A\mathbf x
                +\frac{1}{2} \mathbf x^\top\mathbf A^\top\mathbf L\mathbf y}{2.103} \\
            &\qquad + \highlightcap[blue]{\mathbf x^\top(\bm\Lambda\bm\mu - \mathbf A^\top\mathbf L\mathbf b) + \mathbf y^\top\mathbf L\mathbf b}{2.106} + \mathrm{const.}\\
        \end{align*}
    \end{frame}

    \begin{frame}{Derivation of Joint Distribution $p(\mathbf z)$}
        \vspace*{-5mm}
        \begin{align*}
            \ln p(\mathbf z) 
            &= \ln p(\mathbf x) + \ln p(\mathbf y | \mathbf x) \\
            &= -\frac{1}{2}(\mathbf x - \bm\mu)^\top\bm\Lambda(\mathbf x - \bm\mu) 
            -\frac{1}{2}(\mathbf y - \mathbf A\mathbf x - \mathbf b)^\top\mathbf L(\mathbf y - \mathbf A\mathbf x - \mathbf b)
                + \mathrm{const.} \tag{2.102} \\
            &= \highlight[red]{\displaystyle -\frac{1}{2}\mathbf x^\top(\bm\Lambda + \mathbf A^\top\mathbf L\mathbf A)\mathbf x
                -\frac{1}{2} \mathbf y^\top\mathbf L\mathbf y 
                +\frac{1}{2} \mathbf y^\top\mathbf L\mathbf A\mathbf x
                +\frac{1}{2} \mathbf x^\top\mathbf A^\top\mathbf L\mathbf y} \\
            &\qquad + \highlight[blue]{\mathbf x^\top(\bm\Lambda\bm\mu - \mathbf A^\top\mathbf L\mathbf b) + \mathbf y^\top\mathbf L\mathbf b} + \mathrm{const.}\\
            &= \begin{pmatrix}\mathbf x\\ \mathbf y\end{pmatrix}^\top
            \highlightcap[green]{\begin{pmatrix}
                \bm\Lambda + \mathbf A^\top\mathbf L\mathbf A & -\mathbf A^\top\mathbf L \\
                -\mathbf L\mathbf A& \mathbf L
            \end{pmatrix}}{$\mathbf R$ (Precision mat)}
            \begin{pmatrix}\mathbf x\\ \mathbf y\end{pmatrix}
            + \begin{pmatrix}\mathbf x\\ \mathbf y\end{pmatrix}^\top
                \highlightcap[green]{\begin{pmatrix}\bm\Lambda\bm\mu - \mathbf A^\top\mathbf L\mathbf b \\ \mathbf L\mathbf b\end{pmatrix}}{$\mathbf m$ (mean vec)} \\
            & \quad + \mathrm{const.} \\
            &= \mathbf z^\top\mathbf R\mathbf z + \mathbf z^\top \mathbf m + \mathrm{const.} \\
            &= \mathbf z^\top\mathbf R\mathbf z + \mathbf z^\top \mathbf R \mathbf R^{-1} \mathbf m + \mathrm{const.} \Longrightarrow \mbox{Completing the square!}
        \end{align*}
    \end{frame}
    
    \section{\S2.3.4 Maximum likelihood for the Gaussian}

    \begin{frame}{Maximum likelihood estimation for the Gaussian}
        Maximize the likelihood with regard to $\bm\mu$ and $\bm\Sigma^{-1}$ (i.e. precision $\bm\Lambda$)
        \begin{align*}
            p(\mathbf X | \bm\mu, \bm\Sigma) = \prod_{n=1}^N
            \frac{1}{(2\pi)^{D/2}}\frac{1}{|\bm\Sigma|^{1/2}}
            \exp\left( -\frac{1}{2}(\mathbf x_n - \bm\mu)^\top\bm\Sigma^{-1}(\mathbf x_n - \bm\mu) \right)
        \end{align*}
        By taking logarithm, we obtain:
        \begin{align*}
            \ln p(\mathbf X | \bm\mu, \bm\Sigma) = 
            -\frac{ND}{2}\ln(2\pi) - \frac{N}{2}\ln |\bm\Sigma|
            -\frac{1}{2}\sum_{n=1}^N (\mathbf x_n - \bm\mu)^\top\bm\Sigma^{-1}(\mathbf x_n - \bm\mu)
            \tag{2.118}
        \end{align*}
        Sufficient statistics:
    \end{frame}

    \begin{supframe}{Proof: }
        \begin{align*}
            &-\frac{1}{2}\sum_{n=1}^N (\mathbf x_n - \bm\mu)^\top\bm\Sigma^{-1}(\mathbf x_n - \bm\mu) \\
            &=-\frac{1}{2}\sum_{n=1}^N \mathbf x_n^\top\bm\Sigma^{-1}\mathbf x_n
            + \left( \sum_{n=1}^N \mathbf x_n \right)^\top\bm\Sigma^{-1}\bm\mu
            -\frac{N}{2}\bm\mu^\top\bm\Sigma^{-1}\bm\mu \\
            &=-\frac{1}{2}\tr\left(\bm\Sigma^{-1}\sum_{n=1}^N \mathbf x_n\mathbf x_n^\top\right)
            + \left( \sum_{n=1}^N \mathbf x_n \right)^\top\bm\Sigma^{-1}\bm\mu
            -\frac{N}{2}\bm\mu^\top\bm\Sigma^{-1}\bm\mu \\
            &=-\frac{1}{2}\tr\nbracket{\bm\Sigma^{-1} \abracket{\mathbf x\mathbf x^\top}}
            + \abracket{\mathbf x}^\top\bm\Sigma^{-1}\bm\mu
            -\frac{N}{2}\bm\mu^\top\bm\Sigma^{-1}\bm\mu
        \end{align*}
    \end{supframe}

    \begin{frame}{Title}
        Hello metropolis!
    \end{frame}

    \section{\S2.3.5 Sequential estimation}

    \begin{frame}{Title}
        Hello metropolis!
    \end{frame}

    \section{\S2.3.6 Bayesian inference for the Gaussian}

    \begin{frame}{Title}
        Hello metropolis!
    \end{frame}

    \section{\S2.3.7 Student's t-distribution}

    \begin{frame}{Title}
        Hello metropolis!
    \end{frame}

\end{document}
